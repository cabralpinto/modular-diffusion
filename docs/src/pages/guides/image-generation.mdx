---
id: 1.3
title: "Image Generation"
index: true
---

# {frontmatter.title}

In this guide, we'll explore how to leverage Modular Diffusion for image generation. We'll start with a basic setup, progress to more advanced configurations, and include examples of both unconditional and conditional image generation.

> Prerequisites
>
> This guide assumes familiarity with Diffusion Models and PyTorch. If you need a primer on Diffusion Models, consider reviewing introductory materials first.

## Setting Up

### Installation

First, ensure that Modular Diffusion and the appropriate PyTorch version are installed in your environment:

```sh
pip install modular-diffusion
```

Refer to the [PyTorch installation guide](https://pytorch.org/get-started/locally/) to install the correct version for your system.

## Basic Image Generation

### Loading the Dataset

We’ll use the MNIST dataset to illustrate the image generation process. Here’s how to load and preprocess the dataset:

```python
import torch
from torchvision.datasets import MNIST
from torchvision.transforms import ToTensor

x, _ = zip(*MNIST(str(input), transform=ToTensor(), download=True))
x = torch.stack(x) * 2 - 1
```

### Building the Model

Next, we'll build a Diffusion Model using prebuilt components from Modular Diffusion:

```python
import diffusion
from diffusion.data import Identity
from diffusion.loss import Simple
from diffusion.net import UNet
from diffusion.noise import Gaussian
from diffusion.schedule import Linear

model = diffusion.Model(
    data=Identity(x, batch=128, shuffle=True),
    schedule=Linear(1000, 0.9999, 0.98),
    noise=Gaussian(parameter="epsilon", variance="fixed"),
    net=UNet(channels=(1, 64, 128, 256)),
    loss=Simple(parameter="epsilon"),
    device="cuda" if torch.cuda.is_available() else "cpu",
)
```

### Training and Sampling

Train the model and sample images from it:

```python
losses = [*model.train(epochs=20)]
z = model.sample(batch=10)
```

### Saving the Output

Finally, rearrange and save the generated images:

```python
from einops import rearrange
from torchvision.utils import save_image

z = z[torch.linspace(0, z.shape[0] - 1, 10).int()]
z = rearrange(z, "t b c h w -> c (b h) (t w)")
save_image((z + 1) / 2, "output.png")
```

## Conditional Image Generation

To condition the generation process, include labels in your dataset and adjust the model accordingly:

```python
x, y = zip(*MNIST(str(input), transform=ToTensor(), download=True))
x, y = torch.stack(x) * 2 - 1, torch.tensor(y) + 1

from diffusion.guidance import ClassifierFree

model = diffusion.Model(
    data=Identity(x, y, batch=128, shuffle=True),
    schedule=Cosine(steps=1000),
    noise=Gaussian(parameter="epsilon", variance="fixed"),
    net=UNet(channels=(1, 64, 128, 256), labels=10),
    guidance=ClassifierFree(dropout=0.1, strength=2),
    loss=Simple(parameter="epsilon"),
    device="cuda" if torch.cuda.is_available() else "cpu",
)

z = model.sample(y=torch.arange(1, 11))
z = z[torch.linspace(0, z.shape[0] - 1, 10).int()]
z = rearrange(z, "t b c h w -> c (b h) (t w)")
save_image((z + 1) / 2, "conditional_output.png")
```

## Advanced Configurations

### Adding a Validation Loop

To monitor the training process, you can add a validation loop:

```python
for epoch, loss in enumerate(model.train(epochs=20)):
    z = model.sample(batch=10)
    z = z[torch.linspace(0, z.shape[0] - 1, 10).int()]
    z = rearrange(z, "t b c h w -> c (b h) (t w)")
    save_image((z + 1) / 2, f"{epoch}.png")
```

### Customizing the Model

Modular Diffusion allows easy customization. For instance, to use a different noise schedule:

```python
from diffusion.schedule import Cosine

model = diffusion.Model(
    data=Identity(x, batch=128, shuffle=True),
    schedule=Cosine(steps=1000),
    noise=Gaussian(parameter="epsilon", variance="fixed"),
    net=UNet(channels=(1, 64, 128, 256)),
    loss=Simple(parameter="epsilon"),
    device="cuda" if torch.cuda.is_available() else "cpu",
)
```

### Saving and Loading the Model

Save your model for future use:

```python
model.save("model.pt")
```

To load the saved model:

```python
from pathlib import Path

if Path("model.pt").exists():
    model.load("model.pt")
```

## Conclusion

This guide has covered the basics of image generation using Modular Diffusion, from setting up the environment and building a model, to training, sampling, and customizing the model. For more advanced use cases and further details, refer to the library's API reference and additional tutorials.
